{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "name": "extract-skills-from-job-descriptions.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "\n",
    "This project consists of finding a correlation between job descriptions and skills."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from textblob import Word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read data\n",
    "\n",
    "Let's start by reading this data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My\\ Drive/Colab\\ Notebooks/extract\\ skills\\ from\\ job"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ** raw data **\n",
      "\n",
      "                                           job_title  \\\n",
      "0                      Chief Marketing Officer (CMO)   \n",
      "1                                   Registered Nurse   \n",
      "2                                   Dental Hygienist   \n",
      "3                        Senior Salesforce Developer   \n",
      "4  DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL A...   \n",
      "\n",
      "                                         description  \n",
      "0  Who We're Looking For:\\n\\nThe Chief Marketing ...  \n",
      "1  Queens Boulevard Endoscopy Center, an endoscop...  \n",
      "2  Part-time or Full-timedental hygienist positio...  \n",
      "3  Principle Duties & Responsibilities:\\n\\nAnalyz...  \n",
      "4  For FULL Job Announcement, visit our website: ...  \n",
      "\n",
      " ** data shape **\n",
      "\n",
      "(900, 2)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('jobs-title-and-description.csv')\n",
    "## Delete empty rows (In case I missed parsing a row)\n",
    "test = test.dropna()\n",
    "print(\"\\n ** raw data **\\n\")\n",
    "print(test.head())\n",
    "print(\"\\n ** data shape **\\n\")\n",
    "print(test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This data contains job descriptions and is structured into two columns: \n",
    "\n",
    "* job_title : for the job title.\n",
    "* description : raw text describing the job requirements.\n",
    "\n",
    "Let's now check if our data is balanced and therefore eligible to modeling."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are approximatively 30 rows for each job."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess text data\n",
    "Since the data we're now working with is at its rawest form, we need to preprocess it before extracting information from it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/zubair/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/zubair/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/zubair/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/zubair/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger') "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97473/1835933353.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['description'] = test['description'].str.replace('[^\\w\\s]',' ')\n",
      "/tmp/ipykernel_97473/1835933353.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['description'] = test['description'].str.replace('\\d+', '')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stop))\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m## lemmatization\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdescription\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mWord\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlemmatize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mword\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPreprocessed data: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(test\u001B[38;5;241m.\u001B[39mhead())\n",
      "File \u001B[0;32m~/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/pandas/core/series.py:4433\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4324\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4325\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4328\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4329\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4330\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4331\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4332\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4431\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/pandas/core/apply.py:1082\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m   1079\u001B[0m     \u001B[38;5;66;03m# if we are a string, try to dispatch\u001B[39;00m\n\u001B[1;32m   1080\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m-> 1082\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/pandas/core/apply.py:1137\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1131\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m         \u001B[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m         \u001B[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m         \u001B[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[39;00m\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# \"Callable[[Any], Any]\"\u001B[39;00m\n\u001B[0;32m-> 1137\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1140\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1144\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1145\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2870\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     10\u001B[0m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stop))\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m## lemmatization\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([Word(word)\u001B[38;5;241m.\u001B[39mlemmatize() \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39msplit()]))\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPreprocessed data: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(test\u001B[38;5;241m.\u001B[39mhead())\n",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     10\u001B[0m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39msplit() \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stop))\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m## lemmatization\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[43mWord\u001B[49m(word)\u001B[38;5;241m.\u001B[39mlemmatize() \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m x\u001B[38;5;241m.\u001B[39msplit()]))\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPreprocessed data: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(test\u001B[38;5;241m.\u001B[39mhead())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Word' is not defined"
     ]
    }
   ],
   "source": [
    "## Lower case\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join(x.lower()for x in x.split()))\n",
    "## remove tabulation and punctuation\n",
    "test['description'] = test['description'].str.replace('[^\\w\\s]',' ')\n",
    "## digits\n",
    "test['description'] = test['description'].str.replace('\\d+', '')\n",
    "\n",
    "#remove stop words\n",
    "stop = stopwords.words('english')\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "## lemmatization\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "\n",
    "print(\"Preprocessed data: \\n\")\n",
    "print(test.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize data\n",
    "In this step, **we will aggregate our data by job titles** in order to visualy detect the most frequent words for each job."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated job descriptions: \n",
      "\n",
      "                                            job_title  \\\n",
      "0                                       ABA Therapist   \n",
      "1                       Chief Marketing Officer (CMO)   \n",
      "2                        Construction Project Manager   \n",
      "3   DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL A...   \n",
      "4                                    Dental Hygienist   \n",
      "5                                     Diesel Mechanic   \n",
      "6                       Doctor of Veterinary Medicine   \n",
      "7                        Emergency Veterinarian - NYC   \n",
      "8                     Emergency Veterinary Technician   \n",
      "9                        Experienced A level mechanic   \n",
      "10                          Forward Deployed Engineer   \n",
      "11                                       Hair Stylist   \n",
      "12                          Interested in KWT Global?   \n",
      "13                         Lab - Medical Technologist   \n",
      "14                  Lead Pharmacy Technician: Billing   \n",
      "15                       Mammography Technologist PRN   \n",
      "16                          NYS Licensed Psychologist   \n",
      "17                            OT/ICS Systems Engineer   \n",
      "18                               Paid Search Director   \n",
      "19                            Pest Control Technician   \n",
      "20                                            Plumber   \n",
      "21             Principal Incident Response Consultant   \n",
      "22  Principal, Sr. Consultant – Creative Technologist   \n",
      "23                                           RN / LPN   \n",
      "24                                       RN/LPN (PRN)   \n",
      "25  Regional Vice President – Partner Development ...   \n",
      "26                                   Registered Nurse   \n",
      "27                   Senior Estimator/Project Manager   \n",
      "28                        Senior Salesforce Developer   \n",
      "29                            Ultrasound Technologist   \n",
      "\n",
      "                                          description  \n",
      "0   kids learning loft applied behavior analysis s...  \n",
      "1   looking chief marketing officer cmo exempt exe...  \n",
      "2   overview ranked among nation top construction ...  \n",
      "3   full job announcement visit website www advoca...  \n",
      "4   part time full timedental hygienist position a...  \n",
      "5   excavation contractor looking self starter wel...  \n",
      "6   company hiring surge response covidcompany hir...  \n",
      "7   emergency veterinarianthe family joining veg r...  \n",
      "8   veterinary technician veterinary emergency gro...  \n",
      "9   responsibilities diagnose vehicles based obser...  \n",
      "10  addepar potential make huge swath private inve...  \n",
      "11  perform haircuts stylemust nj licenseconfident...  \n",
      "12  interested kwt global see job fits skill set w...  \n",
      "13  travel medical technologist mt one largest rec...  \n",
      "14  company hiring surge response covidcompany hir...  \n",
      "15  want flexible work schedule available cover mo...  \n",
      "16  licensed nys psychologist needed bronx nursing...  \n",
      "17  forescout technologies leader device visibilit...  \n",
      "18  looking national debt relief currently seeking...  \n",
      "19  position pest control professional join team n...  \n",
      "20  established plumbing company looking plumber m...  \n",
      "21  job descriptioncompany background crypsis grou...  \n",
      "22  teecom tech architecture advancing human perfo...  \n",
      "23  owned operated nurses star pediatric home care...  \n",
      "24  friedwald center rehabilitation nursing lookin...  \n",
      "25  departmentrecruitingclassificationexemptlocati...  \n",
      "26  queens boulevard endoscopy center endoscopy as...  \n",
      "27  prepare estimates project managementprepare es...  \n",
      "28  principle duties responsibilities analyze comp...  \n",
      "29  medical imaging office queens seeking full tim...  \n"
     ]
    }
   ],
   "source": [
    "## jda stands for job description aggregated\n",
    "jda = test.groupby(['job_title']).sum().reset_index()\n",
    "print(\"Aggregated job descriptions: \\n\")\n",
    "print(jda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ## Visualize data\n",
    "# jobs_list = jda.job_title.unique().tolist()\n",
    "# for job in jobs_list:\n",
    "\n",
    "#     # Start with one review:\n",
    "#     text = jda[jda.job_title == job].iloc[0].description\n",
    "#     # Create and generate a word cloud image:\n",
    "#     wordcloud = WordCloud().generate(text)\n",
    "#     print(\"\\n***\",job,\"***\\n\")\n",
    "#     # Display the generated image:\n",
    "#     plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The presence of meaningless words such as: Technology, Organization, Company.\n",
    "as well as the presence of the job title itself will be safely deleted from our data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Delete more stop words\n",
    "other_stop_words = ['junior', 'senior','experience','etc','job','work','company','technique',\n",
    "                    'candidate','skill','skills','language','menu','inc','new','plus','years',\n",
    "                   'technology','organization','ceo','cto','account','manager','data','scientist','mobile',\n",
    "                    'developer','product','revenue','strong']\n",
    "\n",
    "test['description'] = test['description'].apply(lambda x: \" \".join(x for x in x.split() if x not in other_stop_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling\n",
    "We are now going to translate this skill-extraction problem into a classification one first.\n",
    "And then extract the most important features from each class.\n",
    "\n",
    "The most important features, in this case, represent the words that most likely will belong to a class ( in our case job title) \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " naive bayes algorithm selected for this training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (720, 2112)\n",
      "test data shape:  (180, 2112)\n"
     ]
    }
   ],
   "source": [
    "## Converting text to features \n",
    "vectorizer = TfidfVectorizer()\n",
    "#Tokenize and build vocabulary\n",
    "X = vectorizer.fit_transform(test.description)\n",
    "y = test.job_title\n",
    "\n",
    "# split data into 80% training and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=109) \n",
    "print(\"train data shape: \",X_train.shape)\n",
    "print(\"test data shape: \",X_test.shape)\n",
    "\n",
    "# Fit model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "## Predict\n",
    "y_predicted = clf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL EVALUATION "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is:  0.9555555555555556\n",
      "Classes: (to help read Confusion Matrix)\n",
      " ['ABA Therapist' 'Chief Marketing Officer (CMO)'\n",
      " 'Construction Project Manager'\n",
      " 'DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY'\n",
      " 'Dental Hygienist' 'Diesel Mechanic' 'Doctor of Veterinary Medicine'\n",
      " 'Emergency Veterinarian - NYC' 'Emergency Veterinary Technician'\n",
      " 'Experienced A level mechanic' 'Forward Deployed Engineer' 'Hair Stylist'\n",
      " 'Interested in KWT Global?' 'Lab - Medical Technologist'\n",
      " 'Lead Pharmacy Technician: Billing' 'Mammography Technologist PRN'\n",
      " 'NYS Licensed Psychologist' 'OT/ICS Systems Engineer'\n",
      " 'Paid Search Director' 'Pest Control Technician' 'Plumber'\n",
      " 'Principal Incident Response Consultant'\n",
      " 'Principal, Sr. Consultant – Creative Technologist' 'RN / LPN'\n",
      " 'RN/LPN (PRN)'\n",
      " 'Regional Vice President – Partner Development (East Coast)'\n",
      " 'Registered Nurse' 'Senior Estimator/Project Manager'\n",
      " 'Senior Salesforce Developer' 'Ultrasound Technologist']\n",
      "Confusion Matrix: \n",
      "[[ 5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   6  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  5  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  7]]\n",
      "Classification Report: \n",
      "                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                             ABA Therapist       1.00      1.00      1.00         5\n",
      "                             Chief Marketing Officer (CMO)       1.00      1.00      1.00         3\n",
      "                              Construction Project Manager       1.00      1.00      1.00         5\n",
      "     DEPUTY EXECUTIVE DIRECTOR, PROGRAM AND LEGAL ADVOCACY       1.00      1.00      1.00         9\n",
      "                                          Dental Hygienist       1.00      1.00      1.00         8\n",
      "                                           Diesel Mechanic       1.00      1.00      1.00         5\n",
      "                             Doctor of Veterinary Medicine       0.50      1.00      0.67         8\n",
      "                              Emergency Veterinarian - NYC       1.00      1.00      1.00         6\n",
      "                           Emergency Veterinary Technician       1.00      1.00      1.00         6\n",
      "                              Experienced A level mechanic       1.00      1.00      1.00         4\n",
      "                                 Forward Deployed Engineer       1.00      1.00      1.00         3\n",
      "                                              Hair Stylist       1.00      1.00      1.00         9\n",
      "                                 Interested in KWT Global?       1.00      1.00      1.00         4\n",
      "                                Lab - Medical Technologist       1.00      1.00      1.00         8\n",
      "                         Lead Pharmacy Technician: Billing       0.00      0.00      0.00         8\n",
      "                              Mammography Technologist PRN       1.00      1.00      1.00         5\n",
      "                                 NYS Licensed Psychologist       1.00      1.00      1.00         3\n",
      "                                   OT/ICS Systems Engineer       1.00      1.00      1.00         4\n",
      "                                      Paid Search Director       1.00      1.00      1.00         7\n",
      "                                   Pest Control Technician       1.00      1.00      1.00         6\n",
      "                                                   Plumber       1.00      1.00      1.00         3\n",
      "                    Principal Incident Response Consultant       1.00      1.00      1.00         5\n",
      "         Principal, Sr. Consultant – Creative Technologist       1.00      1.00      1.00        10\n",
      "                                                  RN / LPN       1.00      1.00      1.00         8\n",
      "                                              RN/LPN (PRN)       1.00      1.00      1.00         6\n",
      "Regional Vice President – Partner Development (East Coast)       1.00      1.00      1.00         5\n",
      "                                          Registered Nurse       1.00      1.00      1.00         6\n",
      "                          Senior Estimator/Project Manager       1.00      1.00      1.00         3\n",
      "                               Senior Salesforce Developer       1.00      1.00      1.00        11\n",
      "                                   Ultrasound Technologist       1.00      1.00      1.00         7\n",
      "\n",
      "                                                  accuracy                           0.96       180\n",
      "                                                 macro avg       0.95      0.97      0.96       180\n",
      "                                              weighted avg       0.93      0.96      0.94       180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zubair/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zubair/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/zubair/Desktop/dashboard/Upwork Ongoing/job match/skills extraction/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#evaluate the predictions\n",
    "print(\"Accuracy score is: \",accuracy_score(y_test, y_predicted))\n",
    "print(\"Classes: (to help read Confusion Matrix)\\n\", clf.classes_)\n",
    "print(\"Confusion Matrix: \")\n",
    "\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction\n",
    "Let's now extract the most meaningful features of each class.\n",
    "\n",
    "To do so, we can access the attribute *feature_log_prob_* from our model which returns the log probability of features given a class.\n",
    "\n",
    "We will next sort the log probabilies descendingly.\n",
    "\n",
    "And finally map the most important tokens to the classes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Output\n",
    "At this step, we have for each class/job a list of the most representative words/tokens found in job descriptions.\n",
    "\n",
    "Let's shrink this list of words to only:\n",
    "* 6 technical skills\n",
    "* 6 adjectives\n",
    "\n",
    "To do so, we use the library *TextBlob* to identify adjectives.\n",
    "\n",
    "Also, given a (non-exhaustive) list of programming languages, we can extract the top technical skills.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "technical_skills = ['python', 'c','r', 'c++','java','hadoop','scala','flask','pandas','spark','scikit-learn',\n",
    "                    'numpy','php','sql','mysql','css','mongdb','nltk','fastai' , 'keras', 'pytorch','tensorflow',\n",
    "                   'linux','Ruby','JavaScript','django','react','reactjs','ai','ui','tableau']\n",
    "feature_array = vectorizer.get_feature_names()\n",
    "# number of overall model features\n",
    "features_numbers = len(feature_array)\n",
    "## max sorted features number\n",
    "n_max = int(features_numbers * 0.1)\n",
    "\n",
    "\n",
    "##initialize output dataframe\n",
    "output = pd.DataFrame()\n",
    "for i in range(0,len(clf.classes_)):\n",
    "    print(\"\\n****\" ,clf.classes_[i],\"****\\n\")\n",
    "    class_prob_indices_sorted = clf.feature_log_prob_[i, :].argsort()[::-1]\n",
    "    raw_skills = np.take(feature_array, class_prob_indices_sorted[:n_max])\n",
    "    print(\"list of unprocessed skills :\")\n",
    "    print(raw_skills)\n",
    "    \n",
    "    ## Extract technical skills\n",
    "    top_technical_skills= list(set(technical_skills).intersection(raw_skills))[:6]\n",
    "    #print(\"Top technical skills\",top_technical_skills)\n",
    "    \n",
    "    ## Extract adjectives\n",
    "    \n",
    "    # Delete technical skills from raw skills list\n",
    "    ## At this steps, raw skills list doesnt contain the technical skills\n",
    "    #raw_skills = [x for x in raw_skills if x not in top_technical_skills]\n",
    "    #raw_skills = list(set(raw_skills) - set(top_technical_skills))\n",
    "\n",
    "    # transform list to string\n",
    "    txt = \" \".join(raw_skills)\n",
    "    blob = TextBlob(txt)\n",
    "    #top 6 adjective\n",
    "    top_adjectives = [w for (w, pos) in TextBlob(txt).pos_tags if pos.startswith(\"JJ\")][:6]\n",
    "    #print(\"Top 6 adjectives: \",top_adjectives)\n",
    "    \n",
    "    output = output.append({'job_title':clf.classes_[i],\n",
    "                        'technical_skills':top_technical_skills,\n",
    "                        'soft_skills':top_adjectives },\n",
    "                       ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Correlation between jobs and skills:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(output.T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}